{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visión por Computador\n",
    "\n",
    "**Grupo 17**:\n",
    "\n",
    "- Sara Expósito Suárez\n",
    "- Alejandro Padrón Ossorio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detección y caracterización de caras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paquetes necesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from PIL import Image, ImageSequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rainbow Puke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar Mediapipe para detección de landmarks faciales\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(static_image_mode=False, max_num_faces=1, min_detection_confidence=0.5)\n",
    "\n",
    "# Cargar el GIF y convertirlo a una lista de fotogramas\n",
    "gif = Image.open(\"rainbow.gif\")\n",
    "gif_frames = [frame.copy() for frame in ImageSequence.Iterator(gif)]\n",
    "\n",
    "# Ajusta la función gif_overlay para cambiar la posición del GIF\n",
    "def gif_overlay(img, frame_position, scale_width):\n",
    "    \"\"\"Superpone el GIF escalado en la posición especificada de la imagen.\"\"\"\n",
    "    \n",
    "    # Seleccionar el cuadro actual del GIF\n",
    "    frame = gif_frames[int(cv2.getTickCount() % len(gif_frames)) % len(gif_frames)]\n",
    "    \n",
    "    # Redimensionar el GIF al tamaño adecuado\n",
    "    frame = frame.resize((scale_width, int(scale_width * frame.size[1] / frame.size[0])))\n",
    "    frame = frame.convert(\"RGBA\")\n",
    "    frame_np = np.array(frame)\n",
    "    \n",
    "    # Coordenadas y dimensiones\n",
    "    mouth_center_x, mouth_center_y = frame_position\n",
    "    gif_height, gif_width = frame_np.shape[:2]\n",
    "\n",
    "    # Ajustar la posición de y para que el borde superior esté en el centro de la boca\n",
    "    top_left_x = mouth_center_x - gif_width // 2\n",
    "    top_left_y = mouth_center_y\n",
    "\n",
    "    # Verificar límites de la imagen para no salirnos\n",
    "    if top_left_y + gif_height > img.shape[0]:\n",
    "        gif_height = img.shape[0] - top_left_y\n",
    "        frame_np = frame_np[:gif_height, :, :]\n",
    "    if top_left_x + gif_width > img.shape[1]:\n",
    "        gif_width = img.shape[1] - top_left_x\n",
    "        frame_np = frame_np[:, :gif_width, :]\n",
    "\n",
    "    # Superponer el GIF en la imagen\n",
    "    for c in range(3):  # Canales RGB\n",
    "        img[top_left_y:top_left_y+gif_height, top_left_x:top_left_x+gif_width, c] = \\\n",
    "            frame_np[:gif_height, :gif_width, c] * (frame_np[:gif_height, :gif_width, 3] / 255.0) + \\\n",
    "            img[top_left_y:top_left_y+gif_height, top_left_x:top_left_x+gif_width, c] * \\\n",
    "            (1.0 - frame_np[:gif_height, :gif_width, 3] / 255.0)\n",
    "\n",
    "def mouth_open(landmarks, threshold=0.05):\n",
    "    \"\"\"Calcula si la boca está abierta basado en la distancia entre puntos específicos.\"\"\"\n",
    "    top_lip = landmarks[13]  # Landmark del labio superior\n",
    "    bottom_lip = landmarks[14]  # Landmark del labio inferior\n",
    "    mouth_height = abs(bottom_lip.y - top_lip.y)\n",
    "    return mouth_height > threshold\n",
    "\n",
    "# Inicializar captura de video\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame = cv2.flip(frame, 1)  # Voltear la imagen para mirarse en el espejo\n",
    "    \n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(rgb_frame)\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            # Obtener coordenadas de los landmarks de la boca\n",
    "            mouth_top = face_landmarks.landmark[13]  # Labio superior\n",
    "            mouth_bottom = face_landmarks.landmark[14]  # Labio inferior\n",
    "            mouth_left = face_landmarks.landmark[78]  # Lado izquierdo de la boca\n",
    "            mouth_right = face_landmarks.landmark[308]  # Lado derecho de la boca\n",
    "            \n",
    "            # Calcular posición y ancho de la boca\n",
    "            mouth_center_x = int((mouth_top.x + mouth_bottom.x) / 2 * frame.shape[1])\n",
    "            mouth_center_y = int((mouth_top.y + mouth_bottom.y) / 2 * frame.shape[0])\n",
    "            mouth_width = int(abs(mouth_right.x - mouth_left.x) * frame.shape[1])\n",
    "\n",
    "            # Verificar si la boca está abierta\n",
    "            if mouth_open(face_landmarks.landmark):\n",
    "                gif_overlay(frame, (mouth_center_x, mouth_center_y), mouth_width)\n",
    "\n",
    "    cv2.imshow(\"Mouth Open Detection with GIF\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparkling Wink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración de MediaPipe\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(refine_landmarks=True)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Cargar la imagen de la estrella y convertirla a RGBA\n",
    "star_img = Image.open(\"sparkles.png\").convert(\"RGBA\")\n",
    "\n",
    "# Función para calcular la distancia vertical entre los párpados de un ojo\n",
    "def eye_aspect_ratio(eye_landmarks):\n",
    "    vertical_dist = np.linalg.norm(np.array([eye_landmarks[1].x, eye_landmarks[1].y]) - \n",
    "                                   np.array([eye_landmarks[5].x, eye_landmarks[5].y]))\n",
    "    horizontal_dist = np.linalg.norm(np.array([eye_landmarks[0].x, eye_landmarks[0].y]) - \n",
    "                                     np.array([eye_landmarks[3].x, eye_landmarks[3].y]))\n",
    "    return vertical_dist / horizontal_dist\n",
    "\n",
    "# Función para superponer la estrella en el ojo\n",
    "def overlay_star(img, position, scale, mirror=False):\n",
    "    star_resized = star_img.resize((scale, scale), Image.LANCZOS)\n",
    "    star_np = np.array(star_resized)\n",
    "\n",
    "    # Convertir la estrella de RGBA a BGR (sin el canal alfa)\n",
    "    star_bgr = cv2.cvtColor(star_np, cv2.COLOR_RGBA2BGR)\n",
    "    alpha = star_np[..., 3] / 255.0  # Canal alfa normalizado\n",
    "\n",
    "    # Si se debe reflejar la estrella en el eje horizontal, reflejar también el canal alfa\n",
    "    if mirror:\n",
    "        star_bgr = cv2.flip(star_bgr, 1)\n",
    "        alpha = np.flip(alpha, axis=1)  # Reflejar el canal alfa también\n",
    "\n",
    "    # Posición en la imagen de destino\n",
    "    x, y = int(position[0] - scale // 2), int(position[1] - scale // 2)\n",
    "\n",
    "    # Asegúrate de que no nos salgamos de los límites de la imagen\n",
    "    h, w = img.shape[:2]\n",
    "    star_h, star_w = star_bgr.shape[:2]\n",
    "    if x < 0 or x + star_w > w or y < 0 or y + star_h > h:\n",
    "        return\n",
    "\n",
    "    # Superponer la estrella sobre la imagen, utilizando el canal alfa para la mezcla\n",
    "    for c in range(3):  # Canales de color BGR\n",
    "        img[y:y+star_h, x:x+star_w, c] = (\n",
    "            star_bgr[:, :, c] * alpha + \n",
    "            img[y:y+star_h, x:x+star_w, c] * (1 - alpha)\n",
    "        )\n",
    "\n",
    "# Iniciar captura de video\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)  # Voltear la imagen para mirarse en el espejo\n",
    "\n",
    "    # Convertir solo a RGB para MediaPipe\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(rgb_frame)\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            left_eye_landmarks = [\n",
    "                face_landmarks.landmark[i] for i in [362, 385, 387, 263, 373, 380]\n",
    "            ]\n",
    "            right_eye_landmarks = [\n",
    "                face_landmarks.landmark[i] for i in [33, 160, 158, 133, 153, 144]\n",
    "            ]\n",
    "\n",
    "            left_ear = eye_aspect_ratio(left_eye_landmarks)\n",
    "            right_ear = eye_aspect_ratio(right_eye_landmarks)\n",
    "\n",
    "            # Determina si hay guiño en el ojo izquierdo o derecho\n",
    "            if right_ear < 0.2 and left_ear > 0.3:\n",
    "                # Guiño del ojo derecho detectado\n",
    "                right_eye_center = (\n",
    "                    int(right_eye_landmarks[0].x * frame.shape[1]),\n",
    "                    int(right_eye_landmarks[0].y * frame.shape[0])\n",
    "                )\n",
    "                \n",
    "                # Desplazamiento hacia la derecha\n",
    "                right_eye_center = (right_eye_center[0] - 20, right_eye_center[1])\n",
    "\n",
    "                overlay_star(frame, right_eye_center, 50, mirror=False)  # Estrella sin reflejo\n",
    "                \n",
    "            elif left_ear < 0.2 and right_ear > 0.3:\n",
    "                # Guiño del ojo izquierdo detectado\n",
    "                left_eye_center = (\n",
    "                    int(left_eye_landmarks[0].x * frame.shape[1]),\n",
    "                    int(left_eye_landmarks[0].y * frame.shape[0])\n",
    "                )\n",
    "                \n",
    "                # Desplazamiento hacia la izquierda\n",
    "                left_eye_center = (left_eye_center[0] + 60, left_eye_center[1])\n",
    "\n",
    "                overlay_star(frame, left_eye_center, 50, mirror=True)  # Estrella reflejada\n",
    "\n",
    "    # Mostrar la imagen directamente en BGR para OpenCV\n",
    "    cv2.imshow(\"Wink Detection with Star Effect\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración de MediaPipe\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(refine_landmarks=True, static_image_mode=False, max_num_faces=1, min_detection_confidence=0.5)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Cargar el GIF del arco iris y convertirlo a una lista de fotogramas\n",
    "gif = Image.open(\"rainbow.gif\")\n",
    "gif_frames = [frame.copy() for frame in ImageSequence.Iterator(gif)]\n",
    "\n",
    "# Cargar la imagen de la estrella y convertirla a RGBA\n",
    "star_img = Image.open(\"sparkles.png\").convert(\"RGBA\")\n",
    "\n",
    "def mouth_open(landmarks, threshold=0.05):\n",
    "    \"\"\"Calcula si la boca está abierta basado en la distancia entre puntos específicos.\"\"\"\n",
    "    top_lip = landmarks[13]  # Landmark del labio superior\n",
    "    bottom_lip = landmarks[14]  # Landmark del labio inferior\n",
    "    mouth_height = abs(bottom_lip.y - top_lip.y)\n",
    "    return mouth_height > threshold\n",
    "\n",
    "# Función para calcular la distancia vertical entre los párpados de un ojo\n",
    "def eye_aspect_ratio(eye_landmarks):\n",
    "    vertical_dist = np.linalg.norm(np.array([eye_landmarks[1].x, eye_landmarks[1].y]) - \n",
    "                                   np.array([eye_landmarks[5].x, eye_landmarks[5].y]))\n",
    "    horizontal_dist = np.linalg.norm(np.array([eye_landmarks[0].x, eye_landmarks[0].y]) - \n",
    "                                     np.array([eye_landmarks[3].x, eye_landmarks[3].y]))\n",
    "    return vertical_dist / horizontal_dist\n",
    "\n",
    "# Función para superponer el GIF (arco iris) en la imagen\n",
    "def gif_overlay(img, frame_position, scale_width):\n",
    "    \"\"\"Superpone el GIF escalado en la posición especificada de la imagen.\"\"\"\n",
    "    \n",
    "    # Seleccionar el cuadro actual del GIF\n",
    "    frame = gif_frames[int(cv2.getTickCount() % len(gif_frames)) % len(gif_frames)]\n",
    "    \n",
    "    # Redimensionar el GIF al tamaño adecuado\n",
    "    frame = frame.resize((scale_width, int(scale_width * frame.size[1] / frame.size[0])))\n",
    "    frame = frame.convert(\"RGBA\")\n",
    "    frame_np = np.array(frame)\n",
    "    \n",
    "    # Coordenadas y dimensiones\n",
    "    mouth_center_x, mouth_center_y = frame_position\n",
    "    gif_height, gif_width = frame_np.shape[:2]\n",
    "\n",
    "    # Ajustar la posición de y para que el borde superior esté en el centro de la boca\n",
    "    top_left_x = mouth_center_x - gif_width // 2\n",
    "    top_left_y = mouth_center_y\n",
    "\n",
    "    # Verificar límites de la imagen para no salirnos\n",
    "    if top_left_y + gif_height > img.shape[0]:\n",
    "        gif_height = img.shape[0] - top_left_y\n",
    "        frame_np = frame_np[:gif_height, :, :]\n",
    "    if top_left_x + gif_width > img.shape[1]:\n",
    "        gif_width = img.shape[1] - top_left_x\n",
    "        frame_np = frame_np[:, :gif_width, :]\n",
    "\n",
    "    # Superponer el GIF en la imagen\n",
    "    for c in range(3):  # Canales RGB\n",
    "        img[top_left_y:top_left_y+gif_height, top_left_x:top_left_x+gif_width, c] = \\\n",
    "            frame_np[:gif_height, :gif_width, c] * (frame_np[:gif_height, :gif_width, 3] / 255.0) + \\\n",
    "            img[top_left_y:top_left_y+gif_height, top_left_x:top_left_x+gif_width, c] * \\\n",
    "            (1.0 - frame_np[:gif_height, :gif_width, 3] / 255.0)\n",
    "\n",
    "# Función para superponer la estrella en el ojo (con posibilidad de reflejarla)\n",
    "def overlay_star(img, position, scale, mirror=False):\n",
    "    star_resized = star_img.resize((scale, scale), Image.LANCZOS)\n",
    "    star_np = np.array(star_resized)\n",
    "\n",
    "    # Convertir la estrella de RGBA a BGR (sin el canal alfa)\n",
    "    star_bgr = cv2.cvtColor(star_np, cv2.COLOR_RGBA2BGR)\n",
    "    alpha = star_np[..., 3] / 255.0  # Canal alfa normalizado\n",
    "\n",
    "    # Si se debe reflejar la estrella en el eje horizontal, reflejar también el canal alfa\n",
    "    if mirror:\n",
    "        star_bgr = cv2.flip(star_bgr, 1)\n",
    "        alpha = np.flip(alpha, axis=1)  # Reflejar el canal alfa también\n",
    "\n",
    "    # Posición en la imagen de destino\n",
    "    x, y = int(position[0] - scale // 2), int(position[1] - scale // 2)\n",
    "\n",
    "    # Asegúrate de que no nos salgamos de los límites de la imagen\n",
    "    h, w = img.shape[:2]\n",
    "    star_h, star_w = star_bgr.shape[:2]\n",
    "    if x < 0 or x + star_w > w or y < 0 or y + star_h > h:\n",
    "        return\n",
    "\n",
    "    # Superponer la estrella sobre la imagen, utilizando el canal alfa para la mezcla\n",
    "    for c in range(3):  # Canales de color BGR\n",
    "        img[y:y+star_h, x:x+star_w, c] = (\n",
    "            star_bgr[:, :, c] * alpha + \n",
    "            img[y:y+star_h, x:x+star_w, c] * (1 - alpha)\n",
    "        )\n",
    "\n",
    "# Inicializar captura de video\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)  # Voltear la imagen para mirarse en el espejo\n",
    "\n",
    "    # Convertir solo a RGB para MediaPipe\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(rgb_frame)\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            left_eye_landmarks = [\n",
    "                face_landmarks.landmark[i] for i in [362, 385, 387, 263, 373, 380]\n",
    "            ]\n",
    "            right_eye_landmarks = [\n",
    "                face_landmarks.landmark[i] for i in [33, 160, 158, 133, 153, 144]\n",
    "            ]\n",
    "\n",
    "            left_ear = eye_aspect_ratio(left_eye_landmarks)\n",
    "            right_ear = eye_aspect_ratio(right_eye_landmarks)\n",
    "\n",
    "            # Detectar si la boca está abierta\n",
    "            mouth_top = face_landmarks.landmark[13]  # Labio superior\n",
    "            mouth_bottom = face_landmarks.landmark[14]  # Labio inferior\n",
    "            mouth_left = face_landmarks.landmark[78]  # Lado izquierdo de la boca\n",
    "            mouth_right = face_landmarks.landmark[308]  # Lado derecho de la boca\n",
    "            \n",
    "            # Calcular posición y ancho de la boca\n",
    "            mouth_center_x = int((mouth_top.x + mouth_bottom.x) / 2 * frame.shape[1])\n",
    "            mouth_center_y = int((mouth_top.y + mouth_bottom.y) / 2 * frame.shape[0])\n",
    "            mouth_width = int(abs(mouth_right.x - mouth_left.x) * frame.shape[1])\n",
    "\n",
    "            # Verificar si la boca está abierta\n",
    "            if mouth_open(face_landmarks.landmark):\n",
    "                gif_overlay(frame, (mouth_center_x, mouth_center_y), mouth_width)\n",
    "\n",
    "            # Determina si hay guiño en el ojo izquierdo o derecho\n",
    "            if right_ear < 0.2 and left_ear > 0.3:\n",
    "                # Guiño del ojo derecho detectado\n",
    "                right_eye_center = (\n",
    "                    int(right_eye_landmarks[0].x * frame.shape[1]),\n",
    "                    int(right_eye_landmarks[0].y * frame.shape[0])\n",
    "                )\n",
    "                right_eye_center = (right_eye_center[0] - 20, right_eye_center[1])\n",
    "                overlay_star(frame, right_eye_center, 50, mirror=False)  # Estrella sin reflejo\n",
    "            elif left_ear < 0.2 and right_ear > 0.3:\n",
    "                # Guiño del ojo izquierdo detectado\n",
    "                left_eye_center = (\n",
    "                    int(left_eye_landmarks[0].x * frame.shape[1]),\n",
    "                    int(left_eye_landmarks[0].y * frame.shape[0])\n",
    "                )\n",
    "                left_eye_center = (left_eye_center[0] + 60, left_eye_center[1])\n",
    "                overlay_star(frame, left_eye_center, 50, mirror=True)  # Estrella reflejada\n",
    "\n",
    "    # Mostrar la imagen final con ambos efectos\n",
    "    cv2.imshow(\"Wink and Rainbow Effect\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VC_P5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
